{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6031837-1dc6-4773-9fa4-b892b6f0e968",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/69/XGBoost_logo.png\"\n",
    "     align=\"right\"\n",
    "     width=\"40%\"/>\n",
    "\n",
    "# XGBoost for Gradient Boosted Trees\n",
    "\n",
    "[XGBoost](https://xgboost.readthedocs.io/en/latest/) is a library used for training gradient boosted supervised machine learning models, and it has a [Dask integration](https://xgboost.readthedocs.io/en/latest/tutorials/dask.html) for distributed training. In this guide, you'll learn how to train an XGBoost model in parallel using Dask and Coiled. Download {download}`this jupyter notebook <dask-xgboost.ipynb>` to follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7754e-88e1-4a6a-bb16-527f64de3d2d",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "In this example we will use a dataset that joins the\n",
    "Uber/Lyft dataset from the [High-Volume For-Hire Services](https://www.nyc.gov/site/tlc/businesses/high-volume-for-hire-services.page), with the [NYC Taxi Zone Lookup Table](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page). \n",
    "\n",
    "This results in a dataset with ~1.4 billion rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357a947-9ccf-43cf-928c-4e072ea88839",
   "metadata": {},
   "source": [
    "## Get a Coiled Cluster\n",
    "\n",
    "To start we need to spin up a Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588327d-b81a-4397-8ba4-55fce39126f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=50,\n",
    "    name=\"xgboost\",\n",
    "    worker_vm_types=[\"r6i.large\"],\n",
    "    scheduler_vm_types=[\"m6i.large\"],\n",
    "    backend_options={\"region\": \"us-east-2\"},\n",
    ")\n",
    "\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2137fe6-a09b-46a2-bd79-f2765a5a58b1",
   "metadata": {},
   "source": [
    "## Load and Engineer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2dab5-6f93-46e1-b52b-fa97c2c5ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_parquet(\n",
    "    \"s3://coiled-datasets/dask-xgboost-example/feature_table.parquet/\"\n",
    ")\n",
    "\n",
    "# Convert dtypes\n",
    "df = df.astype({\n",
    "    c: \"float32\" \n",
    "    for c in df.select_dtypes(include=\"float\").columns.tolist()\n",
    "}).persist()\n",
    "\n",
    "# Categorize\n",
    "df = df.categorize(columns=df.select_dtypes(include=\"category\").columns.tolist())\n",
    "\n",
    "df = df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf580c-4f7c-4564-a35b-9f1ce94cc3bd",
   "metadata": {},
   "source": [
    "## Custom Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4eff6-0174-45b2-9059-3e061e88c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cv_splits(n_folds = 5):\n",
    "    frac = [1 / n_folds] * n_folds\n",
    "    splits = df.random_split(frac, shuffle=True)\n",
    "    for i in range(n_folds):\n",
    "        train = [splits[j] for j in range(n_folds) if j != i]\n",
    "        test = splits[i]\n",
    "        yield dd.concat(train), test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b2949-2252-4ad4-ad34-a2e80c255dc3",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "When using XGBoost with Dask, we need to call the XGBoost Dask interface from the client side. The main difference with XGBoostâ€™s Dask interface is that we pass our Dask client as an additional argument for carrying out the computation. Note that if the `client` parameter below is set to `None`, XGBoost will use the default client returned by Dask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a95362-92ab-4296-9bb1-9874a9eec4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import dask.array as da\n",
    "import xgboost\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "\n",
    "start = datetime.now()\n",
    "scores = []\n",
    "\n",
    "for i, (train, test) in enumerate(make_cv_splits(5)):\n",
    "    print(f\"Train/Test split #{i + 1} / 5\")\n",
    "    y_train = train[\"trip_time\"]\n",
    "    X_train = train.drop(columns=[\"trip_time\"])\n",
    "    y_test = test[\"trip_time\"]\n",
    "    X_test = test.drop(columns=[\"trip_time\"])\n",
    "\n",
    "    d_train = xgboost.dask.DaskDMatrix(None, X_train, y_train, enable_categorical=True)\n",
    "\n",
    "    print(\"Training ...\")\n",
    "    model = xgboost.dask.train(\n",
    "        None,\n",
    "        {\"tree_method\": \"hist\"},\n",
    "        d_train,\n",
    "        num_boost_round=4,\n",
    "        evals=[(d_train, \"train\")],\n",
    "    )\n",
    "\n",
    "    print(\"Scoring ...\")\n",
    "    predictions = xgboost.dask.predict(None, model, X_test)\n",
    "\n",
    "    score = mean_squared_error(\n",
    "        y_test.to_dask_array(),\n",
    "        predictions.to_dask_array(),\n",
    "        squared=False,\n",
    "        compute=False,\n",
    "    )\n",
    "    scores.append(score.reshape(1).persist())\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "\n",
    "scores = da.concatenate(scores).compute()\n",
    "print(f\"RSME={scores.mean()} +/- {scores.std()}\")\n",
    "print(f\"Total time:  {datetime.now() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff006f-1c8b-479f-9cc0-a9d128a1ee46",
   "metadata": {},
   "source": [
    "## Inspect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906d315-2e93-4c24-8b23-98fcebd3659a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48292f1a-09dd-443c-ad9b-1393aee0a510",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ee713-fab6-4660-b034-34023fb4db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coiled]",
   "language": "python",
   "name": "conda-env-coiled-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
