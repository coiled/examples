{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75688ac6-879d-4449-b73e-74f03a5f991f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyzing the National Water Model with Xarray, Dask, and Coiled\n",
    "\n",
    "_This example was adapted from [this notebook](https://github.com/dcherian/dask-demo/blob/main/nwm-aws.ipynb) by Deepak Cherian, Kevin Sampson, and Matthew Rocklin._\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/blxvfGt9av8?si=-F_kY5K3VK4UvuPc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n",
    "\n",
    "## The National Water Model Dataset\n",
    "\n",
    "In this example, we'll perform a county-wise aggregation of output from the National Water Model (NWM) available on the [AWS Open Data Registry](https://registry.opendata.aws/nwm-archive/). You can read more on the NWM from the [Office of Water Prediction](https://water.noaa.gov/about/nwm).\n",
    "\n",
    "## Problem description\n",
    "\n",
    "Datasets with high spatio-temporal resolution can get large quickly, vastly exceeding the resources you may have on your laptop. Dask integrates with Xarray to support parallel computing and you can use Coiled to scale to the cloud.\n",
    "\n",
    "We'll calculate the mean depth to soil saturation for each US county:\n",
    "\n",
    "- Years: 2020\n",
    "- Temporal resolution: 3-hourly land surface output\n",
    "- Spatial resolution: 250 m grid\n",
    "- 6 TB\n",
    "\n",
    "This example relies on a few tools:\n",
    "- `dask` + `coiled` process the dataset in parallel in the cloud\n",
    "- `xarray` + `flox` to work with the multi-dimensional Zarr datset and aggregate to county-level means from the 250m grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd71599-465f-4c97-baaa-19d900d2a070",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start a Coiled cluster\n",
    "\n",
    "To demonstrate calculation on a cloud-available dataset, we will use Coiled to set up a dask cluster in AWS `us-east-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b08a1c-d042-40f2-aaaa-e7665ca85d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    name=\"xarray-nwm\",\n",
    "    region=\"us-east-1\", # close to dataset, avoid egress charges\n",
    "    n_workers=10,\n",
    "    tags={\"project\": \"nwm\"},\n",
    "    scheduler_vm_types=\"r7g.xlarge\", # memory optimized AWS EC2 instances\n",
    "    worker_vm_types=\"r7g.2xlarge\"\n",
    ")\n",
    "\n",
    "client = cluster.get_client()\n",
    "\n",
    "cluster.adapt(minimum=10, maximum=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185966d-6659-482b-bcbb-826b8f30b1e3",
   "metadata": {},
   "source": [
    "### Load NWM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1749a-0d64-4278-823c-892120bf1a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_zarr(\n",
    "    fsspec.get_mapper(\"s3://noaa-nwm-retrospective-2-1-zarr-pds/rtout.zarr\", anon=True),\n",
    "    consolidated=True,\n",
    "    chunks={\"time\": 896, \"x\": 350, \"y\": 350}\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5631a-0974-48fe-a2dc-4cbeb5654838",
   "metadata": {},
   "source": [
    "Each field in this dataset is big!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd51a5-858f-4c43-926f-e212e6d3dd7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.zwattablrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70429a-ad29-46c1-80e5-5b15b8012b47",
   "metadata": {
    "tags": []
   },
   "source": [
    "Subset to a single year subset for demo purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6fb91d-6a02-4afc-8d8a-ec3529f805f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset = ds.zwattablrt.sel(time=slice(\"2020-01-01\", \"2020-12-31\"))\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10701b9e-3607-4734-9a14-094cebc3c26e",
   "metadata": {},
   "source": [
    "### Load county raster for grouping\n",
    "\n",
    "Load a raster TIFF file identifying counties by unique integer with [rioxarray](https://corteva.github.io/rioxarray/html/rioxarray.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c13d54-7bad-4864-92da-aa7c5b2b35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import rioxarray\n",
    "\n",
    "fs = fsspec.filesystem(\"s3\", requester_pays=True)\n",
    "\n",
    "counties = rioxarray.open_rasterio(\n",
    "    fs.open(\"s3://nwm-250m-us-counties/Counties_on_250m_grid.tif\"), chunks=\"auto\"\n",
    ").squeeze()\n",
    "\n",
    "# remove any small floating point error in coordinate locations\n",
    "_, counties_aligned = xr.align(subset, counties, join=\"override\")\n",
    "\n",
    "counties_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f28f8-8548-4bbc-ab64-e5efaf21bf3c",
   "metadata": {},
   "source": [
    "We'll need the unique county IDs later, calculate that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b2fab-b576-41a7-b0ec-2f37aba924bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "county_id = np.unique(counties_aligned.data).compute()\n",
    "county_id = county_id[county_id != 0]\n",
    "print(f\"There are {len(county_id)} counties!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b5ebe-d01a-46b4-b0c5-ce1052af4a4c",
   "metadata": {},
   "source": [
    "### GroupBy with flox\n",
    "\n",
    "We could run the computation as:\n",
    "\n",
    "```python\n",
    "subset.groupby(counties_aligned).mean()\n",
    "```\n",
    "\n",
    "This would use flox in the background, however, it would also load `counties_aligned` into memory. To avoid egress charges, you can use `flox.xarray` which allows you to lazily groupby a Dask array (here `counties_aligned`) as long as you pass in the expected group labels in `expected_groups`. See the [flox documentation](https://flox.readthedocs.io/en/latest/intro.html#with-dask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c98fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flox.xarray\n",
    "\n",
    "county_mean = flox.xarray.xarray_reduce(\n",
    "    subset,\n",
    "    counties_aligned.rename(\"county\"),\n",
    "    func=\"mean\",\n",
    "    expected_groups=(county_id,),\n",
    ")\n",
    "\n",
    "county_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35efab0-9783-43e6-ab70-bb50a27629ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_mean.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e9079e-5aac-4ac2-9440-0b520f0cac76",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cc83e-ad8e-4451-90a9-877f39097c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# since our dataset is much smaller now, we no longer need cloud resources\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a84a45-7d68-4be0-8b13-28aca2a0a122",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f358457",
   "metadata": {},
   "source": [
    "Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186edb79-06ac-4207-b3d8-251b39254211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read county shapefile, combo of state FIPS code and county FIPS code as multi-index\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "\n",
    "counties = gpd.read_file(\n",
    "    \"https://www2.census.gov/geo/tiger/GENZ2022/shp/cb_2022_us_county_20m.zip\"\n",
    ").to_crs(\"EPSG:3395\")\n",
    "counties[\"STATEFP\"] = counties.STATEFP.astype(int)\n",
    "counties[\"COUNTYFP\"] = counties.COUNTYFP.astype(int)\n",
    "continental = counties[~counties[\"STATEFP\"].isin([2, 15, 72])].set_index([\"STATEFP\", \"COUNTYFP\"])\n",
    "\n",
    "# Interpret `county` as combo of state FIPS code and county FIPS code. Set multi-index:\n",
    "yearly_mean = county_mean.mean(\"time\")\n",
    "yearly_mean.coords[\"STATEFP\"] = (yearly_mean.county // 1000).astype(int)\n",
    "yearly_mean.coords[\"COUNTYFP\"] = np.mod(yearly_mean.county, 1000).astype(int)\n",
    "yearly_mean = yearly_mean.drop_vars(\"county\").set_index(county=[\"STATEFP\", \"COUNTYFP\"])\n",
    "\n",
    "# join\n",
    "continental[\"zwattablrt\"] = yearly_mean.to_dataframe()[\"zwattablrt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d98d2-a207-4dc4-bf22-da732d41d445",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f52f16-1a11-448b-bc01-e278e093d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "continental.hvplot(\n",
    "    c=\"zwattablrt\",\n",
    "    cmap='turbo_r',\n",
    "    title=\"Mean Depth to Soil Saturation in 2020 by US County (meters)\",\n",
    "    xaxis=None,\n",
    "    yaxis=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba2756-10e4-49be-a900-e25fb80b2818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
