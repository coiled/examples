{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6196c9-ba8e-4fa6-bb98-56d2a1679631",
   "metadata": {},
   "source": [
    "<img src=\"https://warehouse-camo.ingress.cmh1.psfhosted.org/73fb6073b2bac71a627a410020353c89833c447a/68747470733a2f2f6769746875622e636f6d2f686f6c6f76697a2f646174617368616465722f7261772f6d61696e2f646f632f5f7374617469632f6c6f676f5f737461636b65642e706e67\"\n",
    "     align=\"right\"\n",
    "     width=\"20%\"/>\n",
    "\n",
    "Visualize 1,000,000,000 Points\n",
    "==============================\n",
    "\n",
    "In this notebook we process roughly one billion points and set them up for interactive visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e68108-29fe-4bec-8800-48a488caffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import datashader\n",
    "import hvplot.dask\n",
    "import coiled\n",
    "from dask.distributed import Client, wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649d478-bce0-4b6f-a39d-3611859a81cf",
   "metadata": {},
   "source": [
    "## Create Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f0f8f-79f9-4133-81a9-e533c35a2a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=20,\n",
    "    name=\"datashader\",\n",
    "    backend_options={\"region_name\": \"us-east-2\"}, \n",
    ") \n",
    "\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c960e-e2e3-4eab-869b-e70002beb2dc",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb9925-a3c3-458d-aa6f-eb9821c15087",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = dd.read_parquet(\n",
    "    \"s3://coiled-datasets/dask-book/nyc-tlc/2009-2013/\",\n",
    "    columns=[\"dropoff_longitude\", \"dropoff_latitude\", \"pickup_longitude\", \"pickup_latitude\"]\n",
    ")\n",
    "\n",
    "# clean data to limit to lat-longs near nyc\n",
    "df = df.loc[\n",
    "    (df.dropoff_longitude > -74.1) & (df.dropoff_longitude < -73.7) & \n",
    "    (df.dropoff_latitude > 40.6) & (df.dropoff_latitude < 40.9) &\n",
    "    (df.pickup_longitude > -74.1) & (df.pickup_longitude < -73.7) &\n",
    "    (df.pickup_latitude > 40.6) & (df.pickup_latitude < 40.9)\n",
    "]\n",
    "\n",
    "# now we have to get a DataFrame with just dropoff locations\n",
    "df_drop = df[[\"dropoff_longitude\", \"dropoff_latitude\"]]\n",
    "df_drop[\"journey_type\"] = \"dropoff\"\n",
    "df_drop = df_drop.rename(columns={'dropoff_longitude': 'long', 'dropoff_latitude': 'lat'})\n",
    "\n",
    "\n",
    "# now do the same for pickups\n",
    "df_pick = df[[\"pickup_longitude\", \"pickup_latitude\"]]\n",
    "df_pick[\"journey_type\"] = \"pickup\"\n",
    "df_pick = df_pick.rename(columns={'pickup_longitude': 'long', 'pickup_latitude': 'lat'})\n",
    "\n",
    "# concatenate two dask dataframes\n",
    "df_plot = dd.concat([df_drop, df_pick])\n",
    "\n",
    "df_plot = df_plot.astype({\"journey_type\": \"category\"})\n",
    "df_plot[\"journey_type\"] = df_plot[\"journey_type\"].cat.set_categories([\"dropoff\", \"pickup\"])\n",
    "\n",
    "#partitions are small - better to repartition\n",
    "df_plot = df_plot.persist()\n",
    "df_plot = df_plot.repartition(partition_size=\"256MiB\").persist()\n",
    "\n",
    "print(\"Number of records:\", len(df_plot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cbceaf-97b2-4b83-b384-633037ee2544",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118e81d-4d1f-4c3d-817a-689dd1bd1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "color_key = {\"pickup\": \"#EF1561\", \"dropoff\": \"#1F5AFF\"}\n",
    "\n",
    "df_plot.hvplot.scatter(\n",
    "    x=\"long\", \n",
    "    y=\"lat\", \n",
    "    aggregator=datashader.by(\"journey_type\"), \n",
    "    datashade=True, \n",
    "    cnorm=\"eq_hist\",\n",
    "    frame_width=700, \n",
    "    aspect=1.33, \n",
    "    color_key=color_key\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
