{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e34e5f-9aa3-4d9c-8dab-cc04b3b5022e",
   "metadata": {},
   "source": [
    "# PyTorch GPUs\n",
    "\n",
    "Optuna example that optimizes multi-layer perceptrons using PyTorch.  \n",
    "\n",
    "Modified from https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py\n",
    "\n",
    "In this example, we optimize the validation accuracy of fashion product recognition using\n",
    "PyTorch and FashionMNIST. We optimize the neural network architecture as well as the optimizer\n",
    "configuration. As it is too time consuming to use the whole FashionMNIST dataset,\n",
    "we here use a small subset of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8811e7-af13-436e-85ec-1a8ef651f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example was adapted from the following PyTorch tutorial\n",
    "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torchvision import datasets, transforms\n",
    "from dask.distributed import print\n",
    "\n",
    "def load_data():\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    # Create datasets for training & validation, download if necessary\n",
    "    training_set = datasets.FashionMNIST(os.getcwd(), train=True, transform=transform, download=True)\n",
    "    validation_set = datasets.FashionMNIST(os.getcwd(), train=False, transform=transform, download=True)\n",
    "\n",
    "    # Create data loaders for our datasets; shuffle for training, not for validation\n",
    "    training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "    # Report split sizes\n",
    "    print('Training set has {} instances'.format(len(training_set)))\n",
    "    print('Validation set has {} instances'.format(len(validation_set)))\n",
    "\n",
    "    return training_loader, validation_loader\n",
    "\n",
    "\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loss_fn, optimizer, training_loader, device):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "def train_all_epochs():\n",
    "    #  Confirm that GPU shows up\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        print(f\"Using GPU {torch.cuda.get_device_name(torch.cuda.current_device())} ðŸ˜Ž\\n\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(\"Using CPU ðŸ˜”\\n\")\n",
    "\n",
    "    training_loader, validation_loader = load_data()\n",
    "    model = GarmentClassifier().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    epochs = 5\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'EPOCH {epoch + 1}:')\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(model, loss_fn, optimizer, training_loader, device)\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        # Set the model to evaluation mode, disabling dropout and using population\n",
    "        # statistics for batch normalization.\n",
    "        model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "\n",
    "                # Move to GPU\n",
    "                vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        # Return the best model\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            best_model = model\n",
    "\n",
    "    print(f\"Model on CUDA device: {next(best_model.parameters()).is_cuda}\")\n",
    "\n",
    "    # Move model to CPU so it can be serialized and returned to local machine\n",
    "\n",
    "    return best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95510b24-123d-4bb4-8249-a0edb003582b",
   "metadata": {},
   "source": [
    "## Run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade8f94-9008-443c-93e1-6da90d80efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_all_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebb91d8-9c2d-408d-9c3c-a0e9535106f1",
   "metadata": {},
   "source": [
    "## Run on GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59f138-f84f-4319-9a54-821dd0525d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "\n",
    "@coiled.function(\n",
    "    vm_type=\"g5.xlarge\",\n",
    "    region=\"us-east-2\",\n",
    "    keepalive=\"1 hour\",\n",
    ")\n",
    "def train_on_gpu():\n",
    "    model = train_all_epochs()\n",
    "    return model.to(\"cpu\")\n",
    "\n",
    "model = train_on_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7ae53-ce21-49f3-856a-87774a19bf37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
